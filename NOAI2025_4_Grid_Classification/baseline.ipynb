{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入需要的包\n",
    "# Import the required packages.\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "from data_download.dataset import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 5)\n",
    "        self.conv4 = nn.Conv2d(32, 64, 5)\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = self.pool(torch.relu(self.conv4(x)))\n",
    "        x = x.view(-1, 64 * 12 * 12)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估函数 Evaluation function.\n",
    "def eval_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device).float().view(-1, 1)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs >= 0.5\n",
    "            corrects += torch.sum(preds == labels).item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = corrects / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数 Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=10):\n",
    "    max_accuracy = 0 # 打印最高准确率 Print the highest accuracy.\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for step,(inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device).float().view(-1, 1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            print(step, loss.item())\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_accuracy = eval_model(model,train_loader, device)\n",
    "        log_message = f'Epoch {epoch+1}/{num_epochs}, Train Accuracy: {train_accuracy:.4f}'\n",
    "        print(log_message)\n",
    "    #print(\"max_accuracy:\", max_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc = 'Test'):\n",
    "            x = batch.to(device)\n",
    "            output = model(x)\n",
    "            pred = torch.argmax(output, dim=1)\n",
    "            preds.extend(pred.cpu().numpy())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "def save_submission_csv(preds, save_name):\n",
    "    df = pd.DataFrame(preds)\n",
    "    df.to_csv(save_name, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "train_dir = 'data_download/train'  #数据地址 #Address of dataset\n",
    "train_file = 'data/train.csv' #训练集标注地址 #Address of training data annotations\n",
    "\n",
    "# 数据预处理 Data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 创建数据加载器\n",
    "# 真实数据label为0，生成图像label为1\n",
    "# Create a data loader\n",
    "# Real data label is 0, generated image label is 1\n",
    "\n",
    "# Train\n",
    "train_dataset = CustomDataset(train_dir, train_file, mode=\"train\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 初始化参数\n",
    "# initialization params\n",
    "# 设置设备 Set up device.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# 创建模型、损失函数和优化器 Create model, loss function, and optimizer.\n",
    "model = MyModel().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "epochs = 10\n",
    "#Train the model and log the process.\n",
    "train_model(model, train_loader, criterion, optimizer, device, num_epochs= epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试阶段\n",
    "val_dir = 'data_download/val'\n",
    "val_file = 'data/val.csv'\n",
    "test_dir = 'data_download/test'\n",
    "test_file = 'data/test.csv'\n",
    "\n",
    "# Val (val: public score, test: private score)\n",
    "val_dataset = CustomDataset(val_dir, val_file, mode=\"val\", transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Test\n",
    "test_dataset = CustomDataset(test_dir, test_file, mode=\"test\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "val_preds = predict(model, val_loader, device)\n",
    "test_preds = predict(model, test_loader, device)\n",
    "# Submission Process\n",
    "save_submission_csv(val_preds, 'submissionA.csv')\n",
    "save_submission_csv(test_preds, 'submissionB.csv')\n",
    "with zipfile.ZipFile('submission.zip', 'w') as zipf:\n",
    "    zipf.write('submissionA.csv')\n",
    "    zipf.write('submissionB.csv')\n",
    "os.remove('submissionA.csv')\n",
    "os.remove('submissionB.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
